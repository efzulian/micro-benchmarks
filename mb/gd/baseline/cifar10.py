# Copyright (c) 2017 OPRECOMP Project
# Fabian Schuiki <fschuiki@iis.ee.ethz.ch>
#
# This file contains utility functions to load the CIFAR-10 training and test
# data set using TensorFlow.
#
# Roughly based on [1,2].
#
# [1]: https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb
# [2]: https://www.tensorflow.org/tutorials/deep_cnn

import tensorflow as tf
import numpy as np


# Dimensions of each image in the dataset.
image_height = 32
image_width = 32
image_depth = 3

# Calculate the data size of each record.
label_bytes = 1 # 1 for CIFAR-10, 2 for CIFAR-100
image_bytes = image_height * image_width * image_depth
record_bytes = label_bytes + image_bytes


# Opens one or more files containing CIFAR-10 image data and yield a tuple
# producing one image and one label.
def open(filenames):
	# Create a reader that will eat individual records from a queue of input
	# files.
	reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)

	# Convert the filenames into a queue that can be passed to the reader.
	if isinstance(filenames, tf.FIFOQueue):
		input_files = filenames
	elif isinstance(filenames, list):
		input_files = tf.train.string_input_producer(filenames)
	else:
		input_files = tf.train.string_input_producer([filenames])

	# Read individual records from the input files.
	record = tf.decode_raw(reader.read(input_files).value, tf.uint8)

	# Slice up the record: The first field is the label, the remainder is the
	# actual pixel data.
	label_data = tf.strided_slice(record, [0], [label_bytes])
	image_data = tf.strided_slice(record, [label_bytes], [label_bytes + image_bytes])

	# Expand the label to a int32 and specify its shape.
	label = tf.cast(label_data, tf.int32)
	label.set_shape([1])

	# Convert the image bytes into a 3D DHW tensor. Then transpose that tensor
	# into HWD representation.
	image_dhw = tf.reshape(image_data, [image_depth, image_height, image_width])
	image_hwd = tf.transpose(image_dhw, [1, 2, 0])

	return (image_hwd, label)


# Prepares an image for processing by either cropping it centrally to 24x24
# pixels, or also applying random distortions yielding a 24x24 pixel image.
def prepare_image(image, distort=False, normalize=True):
	# Cast the image from uint8 to float32.
	image = tf.cast(image, tf.float32)

	# Either distort the image or simply produce a centrally cropped version.
	if distort:
		# Crop to a random 24x24 section of the image.
		image = tf.random_crop(image, [24, 24, 3])

		# Randomly flip the image horizontally.
		image = tf.image.random_flip_left_right(image)

		# Randomize brightness and contrast of the image.
		image = tf.image.random_brightness(image, max_delta=63)
		image = tf.image.random_contrast(image, lower=0.2, upper=1.8)

	else:
		# Centrally crop the image.
		image = tf.image.resize_image_with_crop_or_pad(image, 24, 24)

	# Standardize the image by subtracting off the mean and dividing by the
	# variance of all pixels.
	if normalize:
		image = tf.image.per_image_standardization(image)

	return image


# Reads the labels generated by the prepare_cifar10.py script.
def open_labels(filename, permutation=None, limit=None):
	return np.fromfile(filename, dtype=np.uint8)


# Reads the images generated by the prepare_cifar10.py script.
def open_images(filename, permutation=None, limit=None):
	return np.fromfile(filename, dtype=np.float32).reshape(-1, 24, 24, 3)


def open_labels_single(filename):
	filename = tf.train.string_input_producer([filename])
	reader = tf.FixedLengthRecordReader(record_bytes=1)
	data = tf.decode_raw(reader.read(filename).value, tf.uint8)
	label = tf.reshape(tf.cast(data, tf.int32), [])
	return label


def open_images_single(filename):
	filename = tf.train.string_input_producer([filename])
	reader = tf.FixedLengthRecordReader(record_bytes=24*24*3*4)
	data = tf.decode_raw(reader.read(filename).value, tf.float32)
	image = tf.reshape(data, [24, 24, 3])
	return image


class Batch(object):
	def __init__(self, images=None, labels=None):
		self.images = images
		self.labels = labels

	def __str__(self):
		return "Batch(images=%s, labels=%s)" % (self.images, self.labels)


# Form a batch of multiple images and labels, based on a image and label node.
# Usually you would want to pass in the result of `open()` and `prepare_image()`
# here. A queue of `shuffle_space` input images is constantly maintained. If
# shuffle is true, images are picked randomly out of this space. If is not, they
# are produced in sequence as they appear in the source files. The larger the
# shuffle space, the more randomness. E.g. if `shuffle_space = 10`, the first
# image in the batch is one of the first 10 images in the data set. This acts as
# a kind of "image lookahead" for randomization.
def make_batch(image, label, batch_size=128, shuffle=False, shuffle_space=10000):
	if shuffle:
		images, labels = tf.train.shuffle_batch(
			[image, label],
			num_threads=4,
			batch_size=batch_size,
			capacity=shuffle_space + 3 * batch_size,
			min_after_dequeue=shuffle_space
		)
	else:
		images, labels = tf.train.batch(
			[image, label],
			num_threads=4,
			batch_size=batch_size,
			capacity=shuffle_space
		)

	# Unfortunately the labels now have shape [batch_size, 1], where the last
	# dimension is not really needed.
	return Batch(images, tf.reshape(labels, [batch_size]))


def make_batch_all(images, labels, batch_size, name=None, shuffle=False):
	with tf.name_scope(name, "batch_producer", [images, labels, batch_size]):
		num_samples = images.get_shape()[0]
		assert(labels.get_shape()[0] == num_samples)
		epoch_size = num_samples // batch_size

		if shuffle:
			i = tf.random_uniform([batch_size], maxval=num_samples, dtype=tf.int32)
			x = tf.gather(images, i)
			y = tf.gather(labels, i)

		else:
			i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()
			x = images[i*batch_size : (i+1)*batch_size]
			y = labels[i*batch_size : (i+1)*batch_size]
			x.set_shape([batch_size] + x.get_shape()[1:].as_list())
			y.set_shape([batch_size] + y.get_shape()[1:].as_list())

	batch = Batch(x,y)
	batch.num_samples = num_samples
	batch.epoch_size = epoch_size
	return batch


def make_conv_layer(input, kernel_shape, bias_shape):
	kernel = tf.get_variable(
		"weights",
		kernel_shape,
		initializer=tf.random_normal_initializer(0, 5e-2))
	biases = tf.get_variable(
		"biases",
		bias_shape,
		initializer=tf.constant_initializer(0.0))
	conv = tf.nn.conv2d(input, kernel, strides=[1,1,1,1], padding="SAME")
	return tf.nn.relu(conv + biases)


def make_pool_layer(input, size, stride):
	return tf.nn.max_pool(
		input,
		ksize=[1, size, size, 1],
		strides=[1, stride, stride, 1],
		padding="SAME"
	)


def make_fc_layer(input, num_outputs):
	num_inputs = input.get_shape()[-1].value
	weights = tf.get_variable(
		"weights",
		[num_inputs, num_outputs],
		initializer=tf.random_normal_initializer(0, 4e-2))
	biases = tf.get_variable(
		"biases",
		[num_outputs],
		initializer=tf.constant_initializer(0.0))
	return tf.nn.relu(tf.matmul(input, weights) + biases)



# Construct the graph to perform the inference pass. Maps a batch of input
# images to the 10 classes.
def inference_graph(images):
	with tf.variable_scope("conv1"):
		conv1 = make_conv_layer(images, [5, 5, 3, 64], [64])
		print("conv1:", conv1)
	with tf.variable_scope("pool2"):
		pool2 = make_pool_layer(conv1, 3, 2)
		print("pool2:", pool2)
	with tf.variable_scope("conv3"):
		conv3 = make_conv_layer(pool2, [5, 5, 64, 64], [64])
		print("conv3:", conv3)
	with tf.variable_scope("pool4"):
		pool4 = make_pool_layer(conv3, 3, 2)
		print("pool4:", pool4)

	# Reshape the output into a single dimension for easier fully connected
	# layers.
	dim = int(np.prod(pool4.get_shape()[-3:]))
	print("dim:", dim)
	# batch_size = pool4.get_shape()[0].value
	# print("batch_size:", batch_size)
	reshape = tf.reshape(pool4, [-1, dim])
	print("reshape:", reshape)

	with tf.variable_scope("fc5"):
		fc5 = make_fc_layer(reshape, 384)
		print("fc5:", fc5)
	with tf.variable_scope("fc6"):
		fc6 = make_fc_layer(fc5, 192)
		print("fc6:", fc6)
	with tf.variable_scope("fc7"):
		fc7 = make_fc_layer(fc6, 10)
		print("fc7:", fc7)

	return fc7


# Construct the graph to calculate the loss between the raw classes output by
# the inference graph, and the expected label.
def losses(y, y_):
	return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=y)

def loss(y, y_):
	return tf.reduce_mean(losses(y, y_))


# Construct the graph to calculate the percentage of evluations output by the
# inference graph that coincided with the expected label.
def accuracies(y, y_):
	correct_prediction = tf.equal(tf.argmax(y, 1), tf.cast(y_, tf.int64))
	return tf.cast(correct_prediction, tf.float32)

def accuracy(y, y_):
	return tf.reduce_mean(accuracies(y, y_))
